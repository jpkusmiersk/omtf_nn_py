{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e108fe-72a6-4053-bec2-af1a368594f2",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d419c1d5-26ec-42d6-a6fb-e076dd903666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, time\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9384f-3b1f-4210-b8cf-9cda27c00a8a",
   "metadata": {},
   "source": [
    "## Networks definitions and adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef53a8d-4d7c-4d1d-b914-8429d43fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic NN definitions:\n",
      "dense_layer1_size: 128\n",
      "dense_layer2_size: 64\n",
      "dense_layer3_size: 48\n",
      "dense_layer4_size: 1\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from architecture_definitions import *\n",
    " \n",
    "dir_postfix = get_classic_nn_dir_postfix() \n",
    "    \n",
    "print_Classic_NN()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c86e0-bf1f-4a56-abf8-5762ea739a8f",
   "metadata": {},
   "source": [
    "### Training data set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165627dd-9c1c-41ea-b97a-ff97949c379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from files:\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_April4_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_iPtX_April4_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_iPtX_Feb22_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_Feb22_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_iPtX_Feb15_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_Feb15_chunk_0_filtered.tfrecord.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:19:41.203375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.226840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.227034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.227699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 09:19:41.228493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.228668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.228814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.889140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.889261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.889355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-19 09:19:41.889438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6658 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset <ParallelMapDataset element_spec=(TensorSpec(shape=(4096, 37), dtype=tf.float16, name=None), (TensorSpec(shape=(4096,), dtype=tf.float16, name=None),), TensorSpec(shape=(4096,), dtype=tf.float16, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import io_functions as io\n",
    "importlib.reload(io)\n",
    "\n",
    "batchSize = 4096\n",
    "nEpochs = 1\n",
    "\n",
    "#trainDataDir = \"/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/\"   \n",
    "trainDataDir = \"/home/kbunkow/cms_data/OMTF_data_2020/18_12_2020/\"\n",
    "trainFileNames = glob.glob(trainDataDir+'OMTFHits_pats0x0003_oldSample_files_*_chunk_0.tfrecord.gzip')\n",
    "\n",
    "trainDataDir = \"/scratch_cmsse/alibordi/data/training/\"\n",
    "trainFileNames = glob.glob(trainDataDir+'*tfrecord.gzip')\n",
    "\n",
    "dataset = io.get_Classic_NN_dataset(batchSize, nEpochs, trainFileNames, isTrain=True)\n",
    "\n",
    "print(\"dataset\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abffd6-e9d9-47f0-9198-a84e8c7ac6b6",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d414507a-ce56-42f5-8edf-0a4064d77c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pt_layer_1 (Dense)          (None, 128)               4864      \n",
      "                                                                 \n",
      " pt_layer_2 (Dense)          (None, 64)                8256      \n",
      "                                                                 \n",
      " pt_layer_3 (Dense)          (None, 48)                3120      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 49        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,289\n",
      "Trainable params: 16,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import model_functions as models\n",
    "importlib.reload(models)\n",
    "\n",
    "import io_functions as io\n",
    "importlib.reload(io)\n",
    "\n",
    "networkInputSize = 2 * np.sum(io.getFeaturesMask()) + 1\n",
    "loss_fn = 'mae'\n",
    "\n",
    "model = models.get_Classic_NN(networkInputSize=networkInputSize, loss_fn=loss_fn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a01e5-c7aa-4f68-87f1-c6a4e6270723",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c510c79-fee3-4799-8a21-f8365f8107a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2070 SUPER, compute capability 7.5\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:21:26.233300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48d01be-95ac-416b-8577-c23d3f8924b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start. Current Time = 2023_Apr_19_09_31_47\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:31:47.792785: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-04-19 09:31:47.792808: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2023-04-19 09:31:47.879673: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-04-19 09:31:47.881408: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14/Unknown - 1s 24ms/step - loss: 8.5457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:31:48.373033: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-04-19 09:31:48.373056: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18/Unknown - 1s 25ms/step - loss: 8.4266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:31:48.703752: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-04-19 09:31:48.711037: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2023-04-19 09:31:49.055093: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 2122 callback api events and 2101 activity events. \n",
      "2023-04-19 09:31:49.361172: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-04-19 09:31:50.036954: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49\n",
      "\n",
      "2023-04-19 09:31:50.786620: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30/Unknown - 3s 105ms/step - loss: 8.3565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 09:31:51.081916: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49\n",
      "\n",
      "2023-04-19 09:31:51.087658: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.memory_profile.json.gz\n",
      "2023-04-19 09:31:51.094186: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49\n",
      "Dumped tool data for xplane.pb to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/2023_Apr_19_09_31_47_classic_128_64_48_1/plugins/profile/2023_04_19_09_31_49/fba800be2533.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983/983 [==============================] - 23s 23ms/step - loss: 76.8426 - val_loss: 7.4764\n",
      "Epoch 2/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 73.6910 - val_loss: 7.2464\n",
      "Epoch 3/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 71.9297 - val_loss: 6.9101\n",
      "Epoch 4/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 70.7235 - val_loss: 6.5514\n",
      "Epoch 5/50\n",
      "983/983 [==============================] - 22s 22ms/step - loss: 69.7113 - val_loss: 6.7309\n",
      "Epoch 6/50\n",
      "167/983 [====>.........................] - ETA: 17s - loss: 33.9803\n",
      "Epoch 6: saving model to training/2023_Apr_19_09_31_47_classic_128_64_48_1/cp-0006.ckpt\n",
      "983/983 [==============================] - 21s 22ms/step - loss: 68.9865 - val_loss: 6.2278\n",
      "Epoch 7/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 68.5066 - val_loss: 5.9622\n",
      "Epoch 8/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 68.0294 - val_loss: 6.0112\n",
      "Epoch 9/50\n",
      "983/983 [==============================] - 22s 22ms/step - loss: 67.6740 - val_loss: 5.8424\n",
      "Epoch 10/50\n",
      "983/983 [==============================] - 22s 22ms/step - loss: 67.3701 - val_loss: 5.7526\n",
      "Epoch 11/50\n",
      "337/983 [=========>....................] - ETA: 13s - loss: 61.2206\n",
      "Epoch 11: saving model to training/2023_Apr_19_09_31_47_classic_128_64_48_1/cp-0011.ckpt\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 67.1322 - val_loss: 5.7750\n",
      "Epoch 12/50\n",
      "983/983 [==============================] - 20s 20ms/step - loss: 66.9545 - val_loss: 5.6446\n",
      "Epoch 13/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.7584 - val_loss: 5.7369\n",
      "Epoch 14/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.6721 - val_loss: 5.6055\n",
      "Epoch 15/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.5438 - val_loss: 5.5741\n",
      "Epoch 16/50\n",
      "507/983 [==============>...............] - ETA: 10s - loss: 69.6067\n",
      "Epoch 16: saving model to training/2023_Apr_19_09_31_47_classic_128_64_48_1/cp-0016.ckpt\n",
      "983/983 [==============================] - 22s 22ms/step - loss: 66.4551 - val_loss: 5.5689\n",
      "Epoch 17/50\n",
      "983/983 [==============================] - 20s 21ms/step - loss: 66.4257 - val_loss: 5.5624\n",
      "Epoch 18/50\n",
      "983/983 [==============================] - 20s 20ms/step - loss: 66.4139 - val_loss: 5.5331\n",
      "Epoch 19/50\n",
      "983/983 [==============================] - 20s 20ms/step - loss: 66.3977 - val_loss: 5.4936\n",
      "Epoch 20/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.4744 - val_loss: 5.5272\n",
      "Epoch 21/50\n",
      "679/983 [===================>..........] - ETA: 6s - loss: 73.8807\n",
      "Epoch 21: saving model to training/2023_Apr_19_09_31_47_classic_128_64_48_1/cp-0021.ckpt\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.4025 - val_loss: 5.5339\n",
      "Epoch 22/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.4664 - val_loss: 5.5539\n",
      "Epoch 23/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.5238 - val_loss: 5.5880\n",
      "Epoch 24/50\n",
      "983/983 [==============================] - 21s 21ms/step - loss: 66.5901 - val_loss: 5.6275\n",
      "Epoch 24: early stopping\n",
      "INFO:tensorflow:Assets written to: training/2023_Apr_19_09_31_47_classic_128_64_48_1/assets\n",
      "Training end. Current Time = 2023_Apr_19_09_40_15\n",
      "CPU times: user 28min 57s, sys: 6min 58s, total: 35min 56s\n",
      "Wall time: 8min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training start. Current Time =\", current_time)\n",
    "\n",
    "nEpochs = 50\n",
    "\n",
    "log_dir = \"logs/fit/\" + current_time + dir_postfix\n",
    "job_dir = \"training/\" + current_time + dir_postfix\n",
    "\n",
    "checkpoint_path = job_dir + \"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 5085)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=(10, 20))\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=5, verbose=1)\n",
    "callbacks =  [tensorboard_callback, cp_callback, early_stop_callback]\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "   \n",
    "model.fit(dataset.skip(10), \n",
    "          epochs=nEpochs, shuffle=True,\n",
    "          callbacks=callbacks,\n",
    "          validation_data = dataset.take(10)\n",
    "            )\n",
    "model.save(job_dir, save_format='tf')\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training end. Current Time =\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
