{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e108fe-72a6-4053-bec2-af1a368594f2",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d419c1d5-26ec-42d6-a6fb-e076dd903666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:11:45.783516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-20 13:11:45.783592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-20 13:11:45.785504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-20 13:11:45.801069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob, os, time\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import importlib\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9384f-3b1f-4210-b8cf-9cda27c00a8a",
   "metadata": {},
   "source": [
    "## Networks definitions and adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef53a8d-4d7c-4d1d-b914-8429d43fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic NN definitions:\n",
      "dense_layer1_size: 128\n",
      "dense_layer2_size: 64\n",
      "dense_layer3_size: 32\n",
      "dense_layer4_size: 1\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from architecture_definitions import *\n",
    "\n",
    "dir_postfix = get_classic_nn_dir_postfix() \n",
    "    \n",
    "print_Classic_NN()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c86e0-bf1f-4a56-abf8-5762ea739a8f",
   "metadata": {},
   "source": [
    "### Training data set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165627dd-9c1c-41ea-b97a-ff97949c379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from files:\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_April4_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_Feb15_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_Feb22_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_April14_chunk_0_filtered.tfrecord.gzip\n",
      "/scratch_cmsse/alibordi/data/training/SingleMu_OneOverPt_April20_chunk_0_filtered.tfrecord.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:11:49.484927: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: UNKNOWN ERROR (34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset <_ParallelMapDataset element_spec=(TensorSpec(shape=(4096, 37), dtype=tf.float16, name=None), (TensorSpec(shape=(4096,), dtype=tf.float16, name=None),), TensorSpec(shape=(4096,), dtype=tf.float16, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import io_functions as io\n",
    "importlib.reload(io)\n",
    "\n",
    "batchSize = 4096\n",
    "nEpochs = 1\n",
    "\n",
    "#trainDataDir = \"/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/\"   \n",
    "trainDataDir = \"/home/kbunkow/cms_data/OMTF_data_2020/18_12_2020/\"\n",
    "trainFileNames = glob.glob(trainDataDir+'OMTFHits_pats0x0003_oldSample_files_*_chunk_0.tfrecord.gzip')\n",
    "\n",
    "trainDataDir = \"/scratch_cmsse/alibordi/data/training/\"\n",
    "trainFileNames = glob.glob(trainDataDir+'*OneOverPt*tfrecord.gzip')\n",
    "\n",
    "dataset = io.get_Classic_NN_dataset(batchSize, nEpochs, trainFileNames, isTrain=True)\n",
    "\n",
    "print(\"dataset\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abffd6-e9d9-47f0-9198-a84e8c7ac6b6",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d414507a-ce56-42f5-8edf-0a4064d77c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pt_layer_1 (Dense)          (None, 128)               4864      \n",
      "                                                                 \n",
      " pt_layer_2 (Dense)          (None, 64)                8256      \n",
      "                                                                 \n",
      " pt_layer_3 (Dense)          (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15233 (59.50 KB)\n",
      "Trainable params: 15233 (59.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import model_functions as models\n",
    "importlib.reload(models)\n",
    "\n",
    "import io_functions as io\n",
    "importlib.reload(io)\n",
    "\n",
    "networkInputSize = 2 * np.sum(io.getFeaturesMask()) + 1\n",
    "loss_fn = 'mape'\n",
    "loss_fn = loss_MAPE_MAE\n",
    "\n",
    "model = models.get_Classic_NN(networkInputSize=networkInputSize, loss_fn=loss_fn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a01e5-c7aa-4f68-87f1-c6a4e6270723",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c510c79-fee3-4799-8a21-f8365f8107a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "from keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48d01be-95ac-416b-8577-c23d3f8924b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start. Current Time = 2024_Jan_20_13_11_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:11:50.691252: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-20 13:11:50.691289: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-20 13:11:50.691446: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "     10/Unknown - 3s 81ms/step - loss: 1608.8113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:11:53.868488: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-20 13:11:53.868540: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19/Unknown - 4s 104ms/step - loss: 986.3631 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 13:11:55.257398: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-01-20 13:11:57.207490: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-01-20 13:11:57.208676: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/fit/2024_Jan_20_13_11_50_classic_128_64_32_1/plugins/profile/2024_01_20_13_11_57/zcobl3.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 132s 97ms/step - loss: 133.5154 - val_loss: 90.1773\n",
      "Epoch 2/150\n",
      "1336/1336 [==============================] - 133s 98ms/step - loss: 86.9931 - val_loss: 81.1932\n",
      "Epoch 3/150\n",
      "1336/1336 [==============================] - 128s 95ms/step - loss: 80.3108 - val_loss: 77.0453\n",
      "Epoch 4/150\n",
      "1076/1336 [=======================>......] - ETA: 24s - loss: 76.2999\n",
      "Epoch 4: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0004.ckpt\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 76.0023 - val_loss: 73.8493\n",
      "Epoch 5/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 72.9864 - val_loss: 71.1113\n",
      "Epoch 6/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 70.7908 - val_loss: 70.3947\n",
      "Epoch 7/150\n",
      "1336/1336 [==============================] - 131s 98ms/step - loss: 69.1169 - val_loss: 68.3575\n",
      "Epoch 8/150\n",
      " 817/1336 [=================>............] - ETA: 49s - loss: 67.9454\n",
      "Epoch 8: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0008.ckpt\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 67.8986 - val_loss: 68.2346\n",
      "Epoch 9/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 66.9196 - val_loss: 67.3316\n",
      "Epoch 10/150\n",
      "1336/1336 [==============================] - 128s 95ms/step - loss: 66.1751 - val_loss: 66.4253\n",
      "Epoch 11/150\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 65.6152 - val_loss: 65.7920\n",
      "Epoch 12/150\n",
      " 558/1336 [===========>..................] - ETA: 1:17 - loss: 65.1387\n",
      "Epoch 12: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0012.ckpt\n",
      "1336/1336 [==============================] - 134s 99ms/step - loss: 65.1465 - val_loss: 66.0865\n",
      "Epoch 13/150\n",
      "1336/1336 [==============================] - 128s 95ms/step - loss: 64.7803 - val_loss: 65.6983\n",
      "Epoch 14/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 64.4858 - val_loss: 65.2952\n",
      "Epoch 15/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 64.2551 - val_loss: 64.9826\n",
      "Epoch 16/150\n",
      " 299/1336 [=====>........................] - ETA: 1:41 - loss: 64.2532\n",
      "Epoch 16: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0016.ckpt\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 64.0817 - val_loss: 64.8903\n",
      "Epoch 17/150\n",
      "1336/1336 [==============================] - 133s 99ms/step - loss: 63.9424 - val_loss: 64.8248\n",
      "Epoch 18/150\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 63.8314 - val_loss: 64.7264\n",
      "Epoch 19/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.7448 - val_loss: 64.6216\n",
      "Epoch 20/150\n",
      "  40/1336 [..............................] - ETA: 2:07 - loss: 63.9362\n",
      "Epoch 20: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0020.ckpt\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.6687 - val_loss: 64.6497\n",
      "Epoch 21/150\n",
      "1336/1336 [==============================] - 133s 99ms/step - loss: 63.6135 - val_loss: 64.5842\n",
      "Epoch 22/150\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.5645 - val_loss: 64.5338\n",
      "Epoch 23/150\n",
      "1117/1336 [========================>.....] - ETA: 21s - loss: 63.4771\n",
      "Epoch 23: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0023.ckpt\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.5234 - val_loss: 64.5170\n",
      "Epoch 24/150\n",
      "1336/1336 [==============================] - 133s 99ms/step - loss: 63.4936 - val_loss: 64.4721\n",
      "Epoch 25/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.4670 - val_loss: 64.4503\n",
      "Epoch 26/150\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.4459 - val_loss: 64.4408\n",
      "Epoch 27/150\n",
      " 858/1336 [==================>...........] - ETA: 46s - loss: 63.3126\n",
      "Epoch 27: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0027.ckpt\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.4284 - val_loss: 64.4084\n",
      "Epoch 28/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.4130 - val_loss: 64.4096\n",
      "Epoch 29/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.4023 - val_loss: 64.3979\n",
      "Epoch 30/150\n",
      "1336/1336 [==============================] - 133s 99ms/step - loss: 63.3923 - val_loss: 64.3926\n",
      "Epoch 31/150\n",
      " 599/1336 [============>.................] - ETA: 1:12 - loss: 63.2440\n",
      "Epoch 31: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0031.ckpt\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.3850 - val_loss: 64.3795\n",
      "Epoch 32/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3802 - val_loss: 64.3758\n",
      "Epoch 33/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.3764 - val_loss: 64.3734\n",
      "Epoch 34/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3735 - val_loss: 64.3743\n",
      "Epoch 35/150\n",
      " 340/1336 [======>.......................] - ETA: 1:37 - loss: 63.4765\n",
      "Epoch 35: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0035.ckpt\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.3719 - val_loss: 64.3615\n",
      "Epoch 36/150\n",
      "1336/1336 [==============================] - 130s 97ms/step - loss: 63.3711 - val_loss: 64.3580\n",
      "Epoch 37/150\n",
      "1336/1336 [==============================] - 130s 97ms/step - loss: 63.3713 - val_loss: 64.3504\n",
      "Epoch 38/150\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.3726 - val_loss: 64.3483\n",
      "Epoch 39/150\n",
      "  81/1336 [>.............................] - ETA: 2:11 - loss: 63.5913\n",
      "Epoch 39: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0039.ckpt\n",
      "1336/1336 [==============================] - 133s 98ms/step - loss: 63.3739 - val_loss: 64.3386\n",
      "Epoch 40/150\n",
      "1336/1336 [==============================] - 131s 98ms/step - loss: 63.3768 - val_loss: 64.3310\n",
      "Epoch 41/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.3790 - val_loss: 64.3250\n",
      "Epoch 42/150\n",
      "1158/1336 [=========================>....] - ETA: 17s - loss: 63.3633\n",
      "Epoch 42: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0042.ckpt\n",
      "1336/1336 [==============================] - 130s 97ms/step - loss: 63.3826 - val_loss: 64.3121\n",
      "Epoch 43/150\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 63.3840 - val_loss: 64.3034\n",
      "Epoch 44/150\n",
      "1336/1336 [==============================] - 128s 95ms/step - loss: 63.3852 - val_loss: 64.2982\n",
      "Epoch 45/150\n",
      "1336/1336 [==============================] - 132s 98ms/step - loss: 63.3870 - val_loss: 64.2916\n",
      "Epoch 46/150\n",
      " 899/1336 [===================>..........] - ETA: 41s - loss: 63.2673\n",
      "Epoch 46: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0046.ckpt\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.3878 - val_loss: 64.2872\n",
      "Epoch 47/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3887 - val_loss: 64.2837\n",
      "Epoch 48/150\n",
      "1336/1336 [==============================] - 129s 96ms/step - loss: 63.3884 - val_loss: 64.2804\n",
      "Epoch 49/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3889 - val_loss: 64.2782\n",
      "Epoch 50/150\n",
      " 640/1336 [=============>................] - ETA: 1:08 - loss: 63.2426\n",
      "Epoch 50: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0050.ckpt\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3887 - val_loss: 64.2766\n",
      "Epoch 51/150\n",
      "1336/1336 [==============================] - 127s 94ms/step - loss: 63.3887 - val_loss: 64.2759\n",
      "Epoch 52/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3885 - val_loss: 64.2748\n",
      "Epoch 53/150\n",
      "1336/1336 [==============================] - 130s 97ms/step - loss: 63.3886 - val_loss: 64.2737\n",
      "Epoch 54/150\n",
      " 381/1336 [=======>......................] - ETA: 1:32 - loss: 63.4155\n",
      "Epoch 54: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0054.ckpt\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 63.3884 - val_loss: 64.2740\n",
      "Epoch 55/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3883 - val_loss: 64.2737\n",
      "Epoch 56/150\n",
      "1336/1336 [==============================] - 131s 97ms/step - loss: 63.3881 - val_loss: 64.2738\n",
      "Epoch 57/150\n",
      "1336/1336 [==============================] - 127s 94ms/step - loss: 63.3878 - val_loss: 64.2739\n",
      "Epoch 58/150\n",
      " 122/1336 [=>............................] - ETA: 2:01 - loss: 63.6147\n",
      "Epoch 58: saving model to training/2024_Jan_20_13_11_50_classic_128_64_32_1/cp-0058.ckpt\n",
      "1336/1336 [==============================] - 133s 98ms/step - loss: 63.3878 - val_loss: 64.2741\n",
      "Epoch 59/150\n",
      "1336/1336 [==============================] - 130s 97ms/step - loss: 63.3876 - val_loss: 64.2742\n",
      "Epoch 60/150\n",
      "1336/1336 [==============================] - 130s 96ms/step - loss: 63.3876 - val_loss: 64.2745\n",
      "Epoch 60: early stopping\n",
      "INFO:tensorflow:Assets written to: training/2024_Jan_20_13_11_50_classic_128_64_32_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training/2024_Jan_20_13_11_50_classic_128_64_32_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training end. Current Time = 2024_Jan_20_15_22_41\n",
      "CPU times: user 9h 5min 36s, sys: 2h 6min 52s, total: 11h 12min 29s\n",
      "Wall time: 2h 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training start. Current Time =\", current_time)\n",
    "\n",
    "nEpochs = 150\n",
    "\n",
    "log_dir = \"logs/fit/\" + current_time + dir_postfix\n",
    "job_dir = \"training/\" + current_time + dir_postfix\n",
    "\n",
    "checkpoint_path = job_dir + \"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 5085)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=(10, 20))\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=5, verbose=1)\n",
    "callbacks =  [tensorboard_callback, cp_callback, early_stop_callback]\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "   \n",
    "model.fit(dataset.skip(10), \n",
    "          epochs=nEpochs, shuffle=True,\n",
    "          callbacks=callbacks,\n",
    "          validation_data = dataset.take(10)\n",
    "            )\n",
    "model.save(job_dir, save_format='tf')\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training end. Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b3f82-bcf2-40f4-8811-b63924cf8f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc669a-0deb-489f-9d57-f76e6d176b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
